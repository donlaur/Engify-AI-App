{
  "version": "1.1",
  "generatedAt": "2025-11-09T18:36:04.364Z",
  "totalPatterns": 18,
  "patterns": [
    {
      "id": "chain-of-thought",
      "name": "Chain-of-Thought",
      "category": "COGNITIVE",
      "level": "intermediate",
      "description": "Breaks down reasoning into explicit steps",
      "shortDescription": "Breaks down complex reasoning into explicit steps",
      "fullDescription": "The Chain of Thought Pattern instructs the AI to show its reasoning process step-by-step before arriving at a conclusion. This dramatically improves accuracy on complex problems and makes the AI's logic transparent and verifiable.",
      "howItWorks": "You ask the AI to \"think step by step\" or \"show your reasoning\". The AI then breaks down the problem, considers each part, and builds toward a solution incrementally.",
      "example": "Let's think step by step...",
      "useCases": [
        "Complex problems requiring multi-step reasoning",
        "You need to verify the AI's logic",
        "Mathematical or logical problems",
        "Debugging or troubleshooting scenarios"
      ],
      "bestPractices": [
        "Explicitly ask for step-by-step reasoning",
        "Number the steps if you want specific structure",
        "Use for complex decisions or calculations",
        "Combine with persona for expert-level reasoning"
      ],
      "commonMistakes": [
        "Using it for simple questions (overkill)",
        "Not providing enough context for reasoning",
        "Expecting perfect logic (AI can still make errors)",
        "Forgetting to validate the reasoning yourself"
      ],
      "relatedPatterns": [
        "cognitive-verifier",
        "refinement"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:04:41.036Z",
      "promptCount": 5,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "cognitive-verifier",
      "name": "Cognitive Verifier",
      "category": "COGNITIVE",
      "level": "intermediate",
      "description": "Asks AI to verify its own reasoning",
      "shortDescription": "Instructs the AI to verify its own reasoning and check for errors before presenting conclusions",
      "fullDescription": "The Cognitive Verifier pattern asks the AI to critically examine its own reasoning process, identify potential errors or assumptions, and verify the correctness of its conclusions before presenting them. This pattern improves accuracy by making the AI double-check its work, similar to how a human would review their solution before submitting it. It's especially powerful when combined with Chain-of-Thought, as the AI can verify each step of its reasoning.",
      "howItWorks": "You instruct the AI to: (1) Provide its initial answer or reasoning, (2) Review its own work critically, checking for logical errors, incorrect assumptions, or missing considerations, (3) Verify the correctness of each step or conclusion, and (4) Present the verified answer with confidence. The AI acts as its own quality control mechanism.",
      "example": "Solve this equation: 2x + 5 = 15. What is the value of x?\n\n**Step 1: Solve the equation**\n2x + 5 = 15\n2x = 15 - 5\n2x = 10\nx = 10 / 2\nx = 5\n\n**Step 2: Verify your answer**\nLet me check if x = 5 is correct by substituting back into the original equation:\n2(5) + 5 = 10 + 5 = 15 ✓\n\nThe equation holds true, so x = 5 is correct.",
      "useCases": [
        "Mathematical problems or calculations where accuracy is critical",
        "Logical reasoning tasks where errors could cascade",
        "Code review or debugging where correctness matters",
        "Analysis tasks where assumptions need verification",
        "Any complex problem where self-checking improves quality",
        "Situations where you want to catch errors before they propagate"
      ],
      "bestPractices": [
        "Explicitly ask the AI to verify its reasoning",
        "Specify what aspects to check (logic, math, assumptions, completeness)",
        "Combine with Chain-of-Thought for step-by-step verification",
        "Use for critical tasks where errors are costly",
        "Instruct the AI to show its verification process",
        "Ask for confidence level after verification"
      ],
      "commonMistakes": [
        "Not specifying what to verify (too vague)",
        "Using for simple tasks where verification adds no value",
        "Expecting perfect verification (AI can still make errors)",
        "Not combining with other patterns (works best with Chain-of-Thought)",
        "Asking for verification but not using the results"
      ],
      "relatedPatterns": [
        "chain-of-thought",
        "self-reflection",
        "critique-improve"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:04:57.555Z",
      "promptCount": 5,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "hypothesis-testing",
      "name": "Hypothesis Testing",
      "category": "COGNITIVE",
      "level": "advanced",
      "description": "Generates multiple plausible explanations",
      "shortDescription": "Generates multiple plausible explanations or hypotheses and evaluates them systematically",
      "fullDescription": "The Hypothesis Testing pattern instructs the AI to generate multiple plausible explanations or hypotheses for a problem, then systematically evaluate each one against the available evidence. This is similar to scientific method: propose multiple theories, test them, and determine which best fits the data. This pattern is powerful for complex problems where multiple explanations are possible and you need to find the most likely one.",
      "howItWorks": "You instruct the AI to: (1) Generate 3-5 plausible hypotheses or explanations, (2) For each hypothesis, identify what evidence would support or refute it, (3) Evaluate each hypothesis against the available evidence, (4) Rank hypotheses by likelihood or strength of evidence, and (5) Present the most likely explanation with reasoning.",
      "example": "My application is slow. Use hypothesis testing to identify the root cause.\n\n**Step 1: Generate Hypotheses**\nGenerate 3-5 plausible explanations for why the application might be slow:\n1. Database query performance issues\n2. Network latency or bandwidth constraints\n3. Insufficient server resources (CPU, memory)\n4. Inefficient code or algorithms\n5. External API dependencies causing delays\n\n**Step 2: Evaluate Each Hypothesis**\nFor each hypothesis, identify:\n- What evidence would support it?\n- What evidence would refute it?\n- What diagnostic steps would confirm it?\n\n**Step 3: Rank Hypotheses**\nRank the hypotheses by likelihood based on available evidence and present the most likely cause with your reasoning.",
      "useCases": [
        "Debugging complex systems where multiple root causes are possible",
        "Diagnostic scenarios (medical, technical, business)",
        "Analyzing ambiguous data or situations",
        "Investigating incidents or anomalies",
        "Research problems where multiple theories exist",
        "Decision-making with uncertainty",
        "Root cause analysis"
      ],
      "bestPractices": [
        "Specify the number of hypotheses to generate (3-5 is optimal)",
        "Instruct the AI to evaluate evidence systematically",
        "Ask for ranking based on likelihood or evidence strength",
        "Use for complex problems with multiple possible causes",
        "Combine with diagnostic data or evidence when available",
        "Instruct the AI to explain why each hypothesis is plausible"
      ],
      "commonMistakes": [
        "Generating too many hypotheses (overwhelming)",
        "Not providing enough context or evidence for evaluation",
        "Not ranking hypotheses (all seem equally likely)",
        "Using for simple problems with obvious causes",
        "Not following up with diagnostic steps"
      ],
      "relatedPatterns": [
        "chain-of-thought",
        "cognitive-verifier",
        "flipped-interaction"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:05:16.452Z",
      "promptCount": 5,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "rag",
      "name": "RAG (Retrieval Augmented Generation)",
      "category": "COGNITIVE",
      "level": "advanced",
      "description": "Retrieves information from external knowledge base",
      "shortDescription": "Retrieves relevant information from external knowledge base before generating response",
      "fullDescription": "RAG (Retrieval Augmented Generation) is a pattern that combines information retrieval with text generation. Instead of relying solely on the AI's training data, RAG first retrieves relevant documents or information from a knowledge base (database, vector store, documentation), then uses that retrieved context to generate accurate, up-to-date responses. This pattern is essential for applications that need to reference specific documents, codebases, or knowledge bases that change frequently or contain domain-specific information not in the AI's training data.",
      "howItWorks": "The RAG process involves: (1) **Query**: User asks a question, (2) **Retrieval**: System searches knowledge base (often using semantic search/embeddings) to find relevant documents, (3) **Augmentation**: Retrieved documents are added to the prompt as context, (4) **Generation**: AI generates response using both its training knowledge and the retrieved context. This ensures answers are grounded in your specific data.",
      "example": "Answer this question using our product documentation.\n\n**Question:** What are the key features of our product?\n\n**Step 1: Retrieve Relevant Information**\nSearch our product documentation for:\n- Feature descriptions\n- Product specifications\n- Release notes\n- User guides\n\n**Step 2: Extract Key Information**\nFrom the retrieved documents, identify:\n- Core features\n- Feature descriptions\n- Use cases\n- Technical specifications\n\n**Step 3: Generate Response**\nUsing the retrieved information, provide a comprehensive answer about our product features. Cite specific documents or sections where information came from.\n\n**Available Documentation:**\n[Your knowledge base or documentation source]\n\nGenerate the answer based on the retrieved context.",
      "useCases": [
        "You have a large knowledge base or documentation that changes frequently",
        "You need to answer questions about specific codebases or projects",
        "The AI needs access to information not in its training data",
        "You want to cite sources or provide references",
        "Building chatbots that answer questions about your product/service",
        "Creating AI assistants that reference internal documentation",
        "You need to combine multiple sources of information"
      ],
      "bestPractices": [
        "Use semantic search or embeddings for better retrieval",
        "Retrieve top 3-5 most relevant documents",
        "Include source citations in the response",
        "Instruct the AI to use only information from retrieved context",
        "Handle cases where no relevant information is found",
        "Combine retrieved information with AI's general knowledge appropriately",
        "Use chunking strategies for large documents"
      ],
      "commonMistakes": [
        "Retrieving too many documents (overwhelming context)",
        "Not instructing the AI to prioritize retrieved information",
        "Using simple keyword search instead of semantic search",
        "Not handling cases where retrieval finds nothing",
        "Not citing sources (hard to verify accuracy)",
        "Mixing retrieved context with hallucinated information"
      ],
      "relatedPatterns": [
        "context",
        "few-shot",
        "template"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:06:23.830Z",
      "promptCount": 5,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "reverse-engineering",
      "name": "Reverse Engineering",
      "category": "COGNITIVE",
      "level": "advanced",
      "description": "Deconstructs conclusions to explain reasoning",
      "shortDescription": "Works backward from a conclusion to understand and validate the reasoning that led there",
      "fullDescription": "Reverse engineering in prompt engineering means working backward from a conclusion to understand the reasoning that got you there. Think of it like debugging—when you see unexpected behavior in production, you trace back through the logs and code to find the root cause. This pattern is incredibly useful when you need to validate an AI's logic, teach it better reasoning patterns, or understand why it reached a particular conclusion.\n\nIn practice, this pattern helps you catch logical errors before they cascade into bigger problems. When an AI gives you an answer, you ask it to deconstruct that answer step by step, revealing the assumptions, data, and logic it used. This is similar to a code review where you examine not just what the code does, but why it does it that way. It's especially powerful for catching biased reasoning, incorrect assumptions, or gaps in logic that might not be obvious from the final output alone.",
      "howItWorks": "You instruct the AI to start with its conclusion and work backward, explaining each step of reasoning. For example, if the AI concludes \"This architecture won't scale,\" you ask it to trace back through the reasoning: What metrics did it consider? What assumptions did it make about load patterns? What alternatives did it evaluate? This backward analysis forces the AI to make its reasoning explicit and verifiable.\n\nThe process typically involves: (1) Present the conclusion, (2) Identify the immediate reasoning that led to that conclusion, (3) Break down each piece of reasoning into its supporting evidence and assumptions, (4) Continue tracing backward until you reach the original data or premises. This creates a transparent chain of logic you can validate at each step.",
      "example": {
        "before": "Explain why microservices are better than monoliths.",
        "after": "You concluded that microservices are better than monoliths for this system. Work backward through your reasoning: What specific characteristics of this system led to that conclusion? What trade-offs did you weigh? What assumptions did you make about team size, deployment frequency, and operational complexity?",
        "explanation": "The reverse engineering pattern transforms a simple request into a rigorous analysis by forcing the AI to deconstruct its reasoning. Instead of accepting a conclusion at face value, you get to see the logical chain that produced it, making it easier to spot flawed assumptions or missing considerations."
      },
      "useCases": [
        "Validating AI recommendations before implementing them",
        "Debugging complex technical decisions",
        "Teaching junior engineers how to think through architectural choices",
        "Identifying biases or gaps in reasoning",
        "Code review scenarios where you need to understand the 'why'",
        "Post-mortem analysis of incidents or failures"
      ],
      "bestPractices": [
        "Start with a clear conclusion and ask the AI to work backward systematically",
        "Look for assumptions at each step—these are often where reasoning breaks down",
        "Use this pattern when decisions have significant consequences",
        "Combine with Chain-of-Thought for both forward and backward reasoning",
        "Document the reasoning chain for future reference",
        "Challenge each step to ensure logical consistency"
      ],
      "commonMistakes": [
        "Accepting surface-level explanations without probing deeper",
        "Not questioning the initial assumptions",
        "Using this pattern for simple decisions where it adds no value",
        "Forgetting to validate the data or premises at the end of the chain",
        "Not documenting the revealed reasoning for later use"
      ],
      "relatedPatterns": [
        "chain-of-thought",
        "cognitive-verifier",
        "hypothesis-testing"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:06:05.332Z",
      "promptCount": 0,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "audience-persona",
      "name": "Audience Persona",
      "category": "FOUNDATIONAL",
      "level": "beginner",
      "description": "Tailors the response for a specific audience level",
      "shortDescription": "Tailors responses to match a specific audience's knowledge level and context",
      "fullDescription": "The Audience Persona pattern instructs the AI to adjust its response style, depth, and terminology based on who will be reading it. Just like you'd explain a database outage differently to your CEO versus your engineering team, this pattern ensures the AI matches its communication to the audience's expertise and needs.\n\nThis is particularly powerful when you're creating content for different stakeholders. An explanation of API rate limiting for a technical architect should include implementation details, performance implications, and architectural trade-offs. The same concept explained to a product manager should focus on user impact, business constraints, and feature implications. By specifying the audience, you ensure the AI uses the right level of technical detail and relevant examples.",
      "howItWorks": "You explicitly specify the target audience in your prompt, including their expertise level, role, and relevant background. The AI then adjusts its vocabulary, depth of explanation, examples, and focus areas to match that audience. For instance, \"Explain this to a junior developer\" produces different output than \"Explain this to a VP of Engineering.\"",
      "example": {
        "before": "Explain quantum mechanics.",
        "after": "Explain quantum mechanics to a group of undergraduate physics students who have a basic understanding of classical mechanics but are new to quantum concepts.",
        "explanation": "The Audience Persona pattern improves the prompt by specifying the target audience's knowledge level and background. This ensures the response is appropriately detailed—not too simple, not too complex—and uses examples and analogies that resonate with that specific audience."
      },
      "useCases": [
        "Writing technical documentation for different skill levels",
        "Creating presentations for executives vs. engineers",
        "Building educational content for various learning stages",
        "Communicating technical concepts to non-technical stakeholders",
        "Adapting API documentation for beginners vs. advanced users",
        "Creating onboarding materials for new team members"
      ],
      "bestPractices": [
        "Be specific about the audience's role and expertise level",
        "Mention what the audience already knows to avoid over-explaining",
        "Include the audience's goals or what they care about",
        "Specify industry or domain context if relevant",
        "Indicate what level of technical detail is appropriate",
        "Consider the audience's decision-making needs"
      ],
      "commonMistakes": [
        "Being too vague about who the audience is",
        "Assuming expertise without stating it explicitly",
        "Not considering what the audience already knows",
        "Ignoring the audience's goals or constraints",
        "Using the same audience for all communications",
        "Not testing if the output actually matches the audience level"
      ],
      "relatedPatterns": [
        "persona",
        "context",
        "format"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:01:08.786Z",
      "promptCount": 1,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "few-shot",
      "name": "Few-Shot",
      "category": "FOUNDATIONAL",
      "level": "beginner",
      "description": "Provides examples to guide the AI response format",
      "shortDescription": "Provides examples to guide the AI's responses",
      "fullDescription": "The Few-Shot Pattern teaches the AI by example. You provide 2-5 examples of the input-output pairs you want, and the AI learns the pattern to apply to new inputs. This is incredibly powerful for tasks where explaining the rules is harder than showing examples.",
      "howItWorks": "You structure your prompt with clear examples showing the desired transformation or response style. The AI recognizes the pattern and applies the same logic to new inputs.",
      "example": "Here are 3 examples of good code reviews...",
      "useCases": [
        "The task is easier to show than explain",
        "You want consistent style or format across outputs",
        "You need the AI to follow a specific reasoning pattern",
        "Simple instructions aren't producing the right results"
      ],
      "bestPractices": [
        "Use 2-5 examples (more isn't always better)",
        "Make examples diverse but clear",
        "Show edge cases if relevant",
        "Keep examples concise and focused"
      ],
      "commonMistakes": [
        "Providing too many examples (confuses the pattern)",
        "Using inconsistent examples",
        "Not showing enough variety",
        "Making examples too complex"
      ],
      "relatedPatterns": [
        "template",
        "chain-of-thought"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:01:28.839Z",
      "promptCount": 0,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "persona",
      "name": "Persona",
      "category": "FOUNDATIONAL",
      "level": "beginner",
      "description": "Instructs the AI to adopt a specific role or expert persona",
      "shortDescription": "Assigns a specific role or expertise to the AI",
      "fullDescription": "The Persona Pattern instructs the AI to adopt a specific role, profession, or perspective when generating responses. By defining who the AI should \"be,\" you get responses that match the knowledge, tone, and approach of that persona.",
      "howItWorks": "You explicitly tell the AI to act as a specific expert (e.g., \"You are a senior software architect\"). The AI then filters its responses through that lens, using appropriate terminology, frameworks, and thinking patterns associated with that role.",
      "example": "Act as a senior software engineer with 10 years of experience...",
      "useCases": [
        "You need domain-specific expertise or terminology",
        "You want responses tailored to a specific audience",
        "You need consistent tone and perspective across multiple prompts",
        "You want the AI to apply specialized frameworks or methodologies"
      ],
      "bestPractices": [
        "Be specific about the expertise level (junior, senior, expert)",
        "Include relevant context about the persona's background",
        "Combine with other patterns for better results",
        "Use consistent personas across related prompts"
      ],
      "commonMistakes": [
        "Being too vague (\"act as an expert\" - expert in what?)",
        "Choosing personas that don't match your actual need",
        "Forgetting to maintain the persona throughout the conversation",
        "Using conflicting personas in the same prompt"
      ],
      "relatedPatterns": [
        "context",
        "audience-persona",
        "format"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:00:33.833Z",
      "promptCount": 89,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "zero-shot",
      "name": "Zero-Shot",
      "category": "FOUNDATIONAL",
      "level": "beginner",
      "description": "Direct instruction without examples",
      "shortDescription": "Provides clear, direct instructions without needing examples",
      "fullDescription": "The Zero-Shot pattern means giving the AI a direct, clear instruction without providing examples. It's the simplest prompting approach—just tell the AI what you want, and it uses its pre-trained knowledge to generate a response. This works well for straightforward tasks where the AI already understands the domain and doesn't need examples to clarify what you're asking for.\n\nThink of it like asking a senior engineer to review your code—you don't need to show them examples of good code reviews first. They already know what a code review should look like. Similarly, modern AI models have enough built-in knowledge that for many common tasks, a simple, direct instruction is all you need. The key is making your instruction specific enough that the AI knows exactly what you want.",
      "howItWorks": "You provide a clear, specific instruction that tells the AI what to do, what format to use, or what question to answer. The AI relies on its training to understand and execute your request without needing examples to guide it. The more specific and unambiguous your instruction, the better the result.",
      "example": {
        "before": "Can you help me understand this topic?",
        "after": "Explain the key principles and recent research findings related to quantum entanglement.",
        "explanation": "The zero-shot pattern improves the prompt by being specific and direct. Instead of a vague request for help, you clearly state what information you need (key principles and recent findings) and the exact topic (quantum entanglement). This specificity helps the AI deliver a focused, relevant response."
      },
      "useCases": [
        "Common tasks the AI already understands well",
        "You need quick results without crafting examples",
        "The task is straightforward and doesn't need clarification",
        "You want to test if the AI can handle a task before adding complexity",
        "Generating initial drafts or brainstorming ideas",
        "Simple transformations or formatting tasks"
      ],
      "bestPractices": [
        "Be specific about what you want—clarity is critical",
        "Use precise language to avoid ambiguity",
        "Include relevant context or constraints",
        "Test and refine your instruction based on initial outputs",
        "Start simple and add complexity only if needed",
        "Specify the desired output format if relevant"
      ],
      "commonMistakes": [
        "Being too vague or open-ended",
        "Assuming the AI knows your specific context without stating it",
        "Using zero-shot for complex tasks that need examples",
        "Not providing enough detail about what you want",
        "Forgetting to specify important constraints or requirements"
      ],
      "relatedPatterns": [
        "few-shot",
        "persona",
        "template"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:02:27.489Z",
      "promptCount": 0,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "critique-improve",
      "name": "Critique & Improve",
      "category": "ITERATIVE",
      "level": "intermediate",
      "description": "AI critiques and refines its own output",
      "shortDescription": "AI evaluates and improves its own output through iterative refinement",
      "fullDescription": "The Critique & Improve pattern creates a feedback loop where the AI generates an initial response, then critically reviews and refines it in a separate step. Think of it like pair programming—one role writes the code, the other reviews it for issues. Here, the AI plays both roles across multiple turns, first generating content, then stepping back to evaluate it with fresh perspective, identifying flaws, and producing an improved version.\n\nThis pattern is particularly useful when quality matters more than speed. Instead of accepting the first draft, you get the AI to act as its own editor, checking for clarity, completeness, logical errors, or style issues. It's similar to the peer review process in software development or academic publishing, where external critique leads to stronger final output. The iterative nature helps catch issues that might not be obvious during initial generation.",
      "howItWorks": "You instruct the AI to follow a two-phase process: (1) Generate an initial response to your request, (2) Critically evaluate that response, looking for specific issues like logical gaps, unclear explanations, missing information, or style problems, (3) Create an improved version that addresses the identified issues. This can be repeated across multiple turns for further refinement.\n\nThe key is making the critique phase explicit and defining what to look for—clarity, accuracy, completeness, tone, or whatever matters for your use case.",
      "example": {
        "before": "Summarize the key findings of this research paper.",
        "after": "Summarize the key findings of this research paper. After providing the initial summary, critique the clarity and completeness of your summary. Then, refine the summary to enhance its clarity and ensure all significant findings are covered.",
        "explanation": "The Critique & Improve pattern transforms a simple request into a quality-focused process. By explicitly asking the AI to review and refine its own work, you get a more polished result that's been checked for gaps and clarity issues."
      },
      "useCases": [
        "Writing important documentation or proposals",
        "Code generation where quality and correctness matter",
        "Creating content that will be published or shared widely",
        "Complex analysis that benefits from multiple perspectives",
        "Situations where you want to reduce human review time",
        "Educational scenarios where showing the revision process is valuable"
      ],
      "bestPractices": [
        "Specify what aspects to critique (clarity, accuracy, completeness, style)",
        "Use clear separation between generation and critique phases",
        "Define quality criteria upfront so the AI knows what to check for",
        "Iterate multiple times for high-stakes outputs",
        "Combine with persona pattern for expert-level critique",
        "Ask the AI to explain what it improved and why"
      ],
      "commonMistakes": [
        "Not specifying what to look for in the critique (too vague)",
        "Expecting perfection—AI can still miss issues",
        "Using for simple tasks where iteration adds no value",
        "Not providing enough context for meaningful critique",
        "Skipping the critique and just asking for revision",
        "Forgetting to validate the final output yourself"
      ],
      "relatedPatterns": [
        "self-reflection",
        "cognitive-verifier",
        "chain-of-thought"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:07:19.647Z",
      "promptCount": 0,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "flipped-interaction",
      "name": "Flipped Interaction",
      "category": "ITERATIVE",
      "level": "intermediate",
      "description": "AI takes control of conversation, asking questions to gather sufficient context for complex tasks",
      "shortDescription": "AI takes control of conversation, asking questions to gather sufficient context for complex tasks",
      "fullDescription": "The Flipped Interaction pattern instructs the AI to act as an expert diagnostician or requirements-gatherer, taking control of the conversation by asking the user questions one at a time until it has gathered sufficient context to perform a complex task. This solves the \"low-context prompt\" problem by having the AI guide the user through the information-gathering process.",
      "howItWorks": "You instruct the AI to act as an expert in a specific domain (e.g., \"Act as a senior SRE\") and ask the user questions one by one, rather than expecting the user to provide all context upfront. The AI uses its domain expertise to determine what information is needed and asks for it systematically.",
      "example": "Act as a senior SRE and ask me questions one by one (e.g., \"kubectl describe pod\", \"kubectl logs\") until you have enough info to diagnose the crash loop.",
      "useCases": [
        "Users don't know what information to provide",
        "Diagnostic or troubleshooting scenarios",
        "Requirements gathering for complex tasks",
        "Debugging workflows where step-by-step data collection is needed",
        "Expert consultations where the AI needs to guide the conversation",
        "Compliance audits or structured reviews"
      ],
      "bestPractices": [
        "Use a strong persona pattern (expert role)",
        "Instruct the AI to ask one question at a time",
        "Have the AI wait for user responses before proceeding",
        "Use for diagnostic, troubleshooting, or requirements-gathering tasks",
        "Specify when the AI should stop asking and provide a solution",
        "Make it clear this is a multi-turn conversation"
      ],
      "commonMistakes": [
        "Not specifying the expert persona clearly",
        "Allowing the AI to ask all questions at once",
        "Not defining when to stop asking questions",
        "Using for simple tasks where direct instruction works better",
        "Not making it clear this requires multiple interactions"
      ],
      "relatedPatterns": [
        "persona",
        "question-refinement",
        "chain-of-thought"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:08:41.413Z",
      "promptCount": 1,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "question-refinement",
      "name": "Question Refinement",
      "category": "ITERATIVE",
      "level": "intermediate",
      "description": "AI asks clarifying questions before responding",
      "shortDescription": "AI asks clarifying questions to narrow scope before providing an answer",
      "fullDescription": "The Question Refinement pattern instructs the AI to ask clarifying questions before diving into an answer. Instead of making assumptions about what you're really asking, the AI identifies ambiguities, missing context, or areas where more specificity would improve the response quality. This is like a good engineering discussion—before solving a problem, you make sure everyone's talking about the same thing.\n\nThis pattern is especially valuable when dealing with broad or ambiguous requests. Rather than the AI guessing what you mean and potentially going down the wrong path, it asks targeted questions to narrow the scope and ensure its response actually addresses your needs. It's similar to how a senior engineer might respond to a vague bug report by asking for specific reproduction steps, environment details, or error messages before diagnosing the issue.",
      "howItWorks": "You instruct the AI to analyze your question, identify what's unclear or ambiguous, and ask 1-3 specific clarifying questions before providing a full response. The AI should focus on questions that significantly impact the answer—things like scope, context, constraints, or specific use cases. After you answer the clarifying questions, the AI provides a more targeted, relevant response.",
      "example": {
        "before": "What are the effects of climate change on biodiversity?",
        "after": "What are the effects of climate change on biodiversity in tropical rainforests? Are there specific species or ecosystems you want to focus on, and is there a particular timeframe you are interested in?",
        "explanation": "The Question Refinement pattern improves the prompt by identifying what's too broad and asking targeted questions to narrow the scope. Instead of a generic answer about climate change and biodiversity globally, the AI can now provide a focused response about tropical rainforests in a specific timeframe."
      },
      "useCases": [
        "Initial requests are vague or broad",
        "Multiple interpretations are possible",
        "You want to ensure the AI understands your specific context",
        "Requirements gathering at the start of a project",
        "Exploratory conversations where scope isn't yet defined",
        "Preventing wasted effort from misunderstood requests"
      ],
      "bestPractices": [
        "Limit clarifying questions to 1-3 most critical items",
        "Ask questions that significantly impact the response",
        "Make questions specific and actionable",
        "Combine with persona pattern for domain-specific questioning",
        "Use when the initial request is genuinely ambiguous",
        "Don't overuse—only when clarification adds real value"
      ],
      "commonMistakes": [
        "Asking too many clarifying questions (overwhelming)",
        "Asking questions about things that are already clear",
        "Not following up with the actual answer after clarification",
        "Using this pattern for simple, unambiguous requests",
        "Asking vague clarifying questions that don't narrow scope",
        "Not explaining why you're asking each question"
      ],
      "relatedPatterns": [
        "flipped-interaction",
        "persona",
        "context"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:08:24.961Z",
      "promptCount": 0,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "self-reflection",
      "name": "Self-Reflection / Internalized Critique",
      "category": "ITERATIVE",
      "level": "advanced",
      "description": "Single-prompt technique where AI generates, reviews, and improves its own response before presenting",
      "shortDescription": "Single-prompt technique where AI generates, reviews, and improves its own response before presenting",
      "fullDescription": "The Self-Reflection pattern is a single-prompt technique that instructs the AI to generate a response, then critically review it, identify flaws, and improve it before presenting the final answer. Unlike the iterative Critique & Improve pattern, this happens in a single pass, making it faster and more automatable while producing higher-quality first-pass responses.",
      "howItWorks": "You structure your prompt to instruct the AI to: (1) Generate an initial response, (2) Critically review its own output for errors, style issues, or improvements, (3) Apply the improvements, and (4) Present only the final, improved version. This internalizes the quality control loop.",
      "example": "Generate the Python code. Then, perform a self-reflection, checking for bugs, style guide violations, and inefficiencies. Provide only the final, improved code.",
      "useCases": [
        "You need high-quality output in a single pass",
        "Building automated systems where iterative loops are costly",
        "Code generation where correctness is critical",
        "Technical documentation that must be accurate",
        "Any task where self-correction improves quality",
        "You want to reduce the need for human review"
      ],
      "bestPractices": [
        "Define specific criteria for the self-review (bugs, style, performance)",
        "Instruct the AI to provide only the final output, not the reflection process",
        "Use for critical outputs where correctness matters",
        "Combine with persona pattern for expert-level review",
        "Specify the improvement areas explicitly",
        "Use for code, technical documentation, or analytical tasks"
      ],
      "commonMistakes": [
        "Not being specific about what to review",
        "Asking the AI to show its reflection (adds noise)",
        "Using for simple tasks where it adds unnecessary overhead",
        "Not testing if the reflection actually improves quality",
        "Expecting perfect results (still validate)"
      ],
      "relatedPatterns": [
        "critique-improve",
        "cognitive-verifier",
        "chain-of-thought"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:07:41.055Z",
      "promptCount": 0,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "kernel",
      "name": "KERNEL Framework",
      "category": "STRUCTURAL",
      "level": "advanced",
      "description": "Six principles for enterprise-grade prompts",
      "shortDescription": "Six-principle framework for building production-ready, maintainable prompts",
      "fullDescription": "The KERNEL Framework is a systematic approach to designing enterprise-grade prompts that are clear, reliable, and maintainable at scale. The acronym stands for six core principles: Knowledge, Explicitness, Reusability, Non-redundancy, Error-resilience, and Linguistic precision. Think of it as applying software engineering best practices to prompt design—you wouldn't ship production code without considering maintainability, error handling, and clarity. The same applies to prompts in production systems.\n\nThis framework is particularly valuable when building AI systems that multiple teams will use, where prompts need to be versioned and maintained over time, or where consistent behavior across many scenarios is critical. Just like you'd refactor messy code into clean, modular functions, KERNEL helps you structure prompts that are easy to understand, modify, and debug.",
      "howItWorks": "Each KERNEL principle guides a specific aspect of prompt design:\n\n**Knowledge**: Embed relevant domain-specific context directly in the prompt so the AI has what it needs to generate accurate responses.\n\n**Explicitness**: Be crystal clear about what you want—leave no room for misinterpretation. Specify format, constraints, and success criteria.\n\n**Reusability**: Design prompts as modular components that can be used across different scenarios with minimal modification.\n\n**Non-redundancy**: Eliminate unnecessary repetition or contradictory instructions that waste tokens and confuse the AI.\n\n**Error-resilience**: Build in handling for edge cases, invalid inputs, or ambiguous scenarios so the system degrades gracefully.\n\n**Linguistic precision**: Use clear, unambiguous language that the AI can parse reliably, avoiding vague terms or multiple interpretations.",
      "example": {
        "before": "Summarize this research paper.",
        "after": "Summarize the key findings and contributions of the research paper titled 'The Impact of Climate Change on Marine Biodiversity' by Dr. Jane Doe, published in the Journal of Marine Science in 2023. Highlight the methodology used and any significant data trends discussed in the paper.",
        "explanation": "The KERNEL-improved prompt demonstrates Explicitness (specific paper, author, publication), Knowledge (providing context), and Linguistic precision (clear instructions about what to highlight). This reduces ambiguity and ensures the AI focuses on the right document with the right level of detail."
      },
      "useCases": [
        "Building production AI systems with consistent behavior",
        "Creating prompt libraries for teams to share",
        "Systems where prompts need versioning and maintenance",
        "High-stakes applications where reliability matters",
        "Multi-user platforms with diverse use cases",
        "Prompts that need to handle edge cases gracefully"
      ],
      "bestPractices": [
        "Apply all six principles, not just one or two",
        "Start with Knowledge and Explicitness—they have the biggest impact",
        "Design for Reusability by using variables and templates",
        "Test for Error-resilience with edge cases and invalid inputs",
        "Review prompts regularly and refactor for Non-redundancy",
        "Use Linguistic precision to avoid ambiguous phrasing"
      ],
      "commonMistakes": [
        "Applying KERNEL to simple, one-off prompts (overkill)",
        "Focusing only on Explicitness while ignoring Error-resilience",
        "Adding so much Knowledge that the prompt becomes overwhelming",
        "Not testing Reusability across different scenarios",
        "Writing verbose prompts in the name of precision (balance matters)",
        "Forgetting to document why each element is included"
      ],
      "relatedPatterns": [
        "template",
        "structured-output",
        "recipe"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:03:02.216Z",
      "promptCount": 0,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "recipe",
      "name": "Recipe",
      "category": "STRUCTURAL",
      "level": "intermediate",
      "description": "Step-by-step instructions for complex tasks",
      "shortDescription": "Breaks down complex tasks into sequential, numbered steps",
      "fullDescription": "The Recipe pattern provides the AI with a structured, step-by-step approach to completing complex tasks. Like following a cooking recipe, you break down the work into clear, sequential steps that build on each other. This is particularly effective for tasks with multiple phases, dependencies between steps, or where order matters.\n\nThis pattern helps prevent the AI from skipping important steps, taking shortcuts, or approaching the task in the wrong order. It's similar to how you'd write a runbook for deploying a service or a procedure for incident response—each step is explicit, ordered, and the output of one step feeds into the next. By making the process concrete and sequential, you get more reliable, repeatable results.",
      "howItWorks": "You structure your prompt as a numbered sequence of discrete steps, each with a clear action and expected outcome. The AI follows these steps in order, completing each one before moving to the next. You can include conditional logic (\"If X, then do Y, otherwise do Z\"), specify what to do with the output of each step, and define success criteria.\n\nThe key is making each step specific enough to be actionable while keeping the overall flow logical and complete.",
      "example": "First analyze the requirements, then design the solution, finally implement...",
      "useCases": [
        "Multi-phase workflows with clear stages",
        "Tasks where order and dependencies matter",
        "Complex analysis that requires systematic approach",
        "Onboarding or training scenarios",
        "Standard operating procedures",
        "Tasks that need to be repeatable and consistent"
      ],
      "bestPractices": [
        "Number each step clearly (Step 1, Step 2, etc.)",
        "Make each step actionable with clear input and output",
        "Include decision points or conditional logic where needed",
        "Specify what success looks like for each step",
        "Keep steps focused—break very large steps into sub-steps",
        "Test the recipe end-to-end to ensure steps flow logically"
      ],
      "commonMistakes": [
        "Making steps too vague or high-level",
        "Including too many steps (overwhelming)",
        "Forgetting dependencies between steps",
        "Not specifying what to do with outputs from each step",
        "Using for simple tasks that don't need a recipe",
        "Skipping error handling or edge cases"
      ],
      "relatedPatterns": [
        "chain-of-thought",
        "template",
        "structured-output"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:04:25.300Z",
      "promptCount": 1,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "structured-output",
      "name": "Structured Output Generation",
      "category": "STRUCTURAL",
      "level": "intermediate",
      "description": "Forces the AI to output in machine-readable formats (JSON, XML, YAML) for system integration",
      "shortDescription": "Forces the AI to output in machine-readable formats (JSON, XML, YAML) for system integration",
      "fullDescription": "The Structured Output Generation pattern instructs the AI to return responses in a specific, machine-readable format such as JSON, XML, or YAML. This is critical for production engineering systems where AI outputs must be programmatically parsed and integrated into automated workflows, databases, or CI/CD pipelines. Unlike conversational prompts, structured outputs enable reliable system integration.",
      "howItWorks": "You explicitly define the output format using schema definitions (JSON Schema, XML DTD, or YAML structure) and strict instructions to output ONLY the structured data with no additional text. The AI then formats its response according to your specification, making it parseable by other systems.",
      "example": "Return a list of security vulnerabilities as a JSON array, adhering to this JSON Schema... Do not output any text before or after the JSON.",
      "useCases": [
        "You need to integrate AI output into automated systems",
        "Building APIs that return AI-generated data",
        "Creating CI/CD pipelines that process AI responses",
        "Storing AI outputs in databases or data warehouses",
        "You need consistent, parseable data structures",
        "Building agentic systems that process AI outputs programmatically"
      ],
      "bestPractices": [
        "Provide explicit schema definitions (JSON Schema, XML DTD)",
        "Use strict instructions: \"Output ONLY JSON, no text before or after\"",
        "Validate the output format programmatically",
        "Use JSON Schema for complex nested structures",
        "Consider using XML or YAML for domain-specific formats",
        "Test with edge cases to ensure format consistency",
        "Handle parsing errors gracefully in your code"
      ],
      "commonMistakes": [
        "Not being explicit enough about format requirements",
        "Allowing extra text before/after the structured data",
        "Using formats the AI cannot reliably produce",
        "Not validating parsed output",
        "Making schemas too complex or ambiguous",
        "Forgetting to handle malformed responses"
      ],
      "relatedPatterns": [
        "template",
        "constraint",
        "recipe"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:02:59.859Z",
      "promptCount": 0,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "template",
      "name": "Template",
      "category": "STRUCTURAL",
      "level": "beginner",
      "description": "Provides a structured format for the AI to fill in",
      "shortDescription": "Provides a fill-in-the-blank structure with placeholders",
      "fullDescription": "The Template Pattern gives the AI a structured outline with placeholders that it fills in based on your input. This ensures consistent structure while allowing flexible content.",
      "howItWorks": "You provide a template with placeholders (like {feature_name}, {benefit}, etc.) and the AI fills them in with appropriate content based on your context.",
      "example": "Format your response as: Problem | Solution | Impact",
      "useCases": [
        "You need consistent document structure",
        "Creating standardized outputs (user stories, PRDs, etc.)",
        "Generating multiple similar items",
        "Ensuring all required sections are included"
      ],
      "bestPractices": [
        "Use clear, descriptive placeholder names",
        "Provide context for what should fill each placeholder",
        "Keep templates simple and focused",
        "Test with different inputs to ensure flexibility"
      ],
      "commonMistakes": [
        "Too many placeholders (overwhelming)",
        "Vague placeholder names",
        "Rigid templates that don't allow variation",
        "Not providing enough context for filling placeholders"
      ],
      "relatedPatterns": [
        "format",
        "few-shot"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:02:42.919Z",
      "promptCount": 54,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    },
    {
      "id": "visual-separators",
      "name": "Visual Separators",
      "category": "STRUCTURAL",
      "level": "intermediate",
      "description": "Uses delimiters to organize prompt sections",
      "shortDescription": "Uses delimiters like '---' or '###' to clearly separate prompt sections",
      "fullDescription": "The Visual Separators pattern uses delimiters—like lines, hashtags, or symbols—to clearly mark different sections of your prompt. Think of it like using headers and whitespace in code to improve readability. When you have a complex prompt with multiple parts (context, instructions, examples, constraints), visual separators make it easier for both humans and AI to parse the structure.\n\nThis pattern is particularly useful for long or complex prompts where different sections serve different purposes. Just like well-formatted code is easier to debug and maintain, well-structured prompts with clear visual boundaries are easier to understand and modify. It also helps the AI distinguish between different types of information—what's context versus what's instruction versus what's an example.",
      "howItWorks": "You use consistent delimiter patterns to mark sections of your prompt. Common approaches include:\n\n- Triple hashes (###) for section headers\n- Horizontal lines (---) to separate major sections\n- Brackets or XML-like tags (<context>...</context>)\n- Consistent indentation or bullet points\n\nThe key is consistency—use the same delimiters throughout your prompts so the AI learns to recognize the structure. Each section should have a clear purpose (context, task, format, examples, constraints).",
      "example": {
        "before": "Analyze the data on climate change impacts and provide a summary of key findings, including effects on agriculture, water resources, and health.",
        "after": "=== Task ===\nAnalyze the data on climate change impacts.\n\n=== Instructions ===\nProvide a summary of key findings, including:\n- Effects on agriculture\n- Effects on water resources\n- Effects on health\n\n=== Additional Information ===\nConsider recent studies and statistics from reputable sources.",
        "explanation": "Visual separators improve the prompt by clearly marking what's the task, what's the instructions, and what's additional context. This makes it easier to understand, modify, and ensure the AI focuses on the right elements in the right order."
      },
      "useCases": [
        "Complex prompts with multiple sections or types of information",
        "Building reusable prompt templates for teams",
        "Prompts that combine context, examples, and instructions",
        "Long prompts where structure improves clarity",
        "Multi-part tasks with distinct phases",
        "Prompts that need to be maintained or versioned"
      ],
      "bestPractices": [
        "Use consistent delimiters throughout your prompts",
        "Label each section clearly (Task, Context, Examples, Constraints)",
        "Keep sections focused on one type of information",
        "Use visual hierarchy (headers, sub-sections) for complex prompts",
        "Don't overuse—only separate when it adds clarity",
        "Test that the separators actually improve AI understanding"
      ],
      "commonMistakes": [
        "Using too many different delimiter styles (inconsistent)",
        "Over-separating simple prompts that don't need structure",
        "Not labeling sections (separators without context)",
        "Making separators too complex or decorative",
        "Forgetting that separators use tokens (keep them simple)",
        "Using delimiters that might confuse the AI (like code syntax in non-code contexts)"
      ],
      "relatedPatterns": [
        "template",
        "recipe",
        "kernel"
      ],
      "createdAt": "2025-11-05T00:51:40.163Z",
      "updatedAt": "2025-11-06T07:03:47.003Z",
      "promptCount": 0,
      "publishedDate": "2025-01-17",
      "lastUpdated": "2025-01-17",
      "author": "Engify Prompt Engineering Team",
      "reviewedBy": [
        "Engineering Leaders",
        "AI Practitioners"
      ]
    }
  ],
  "totals": {
    "byCategory": {
      "COGNITIVE": 5,
      "FOUNDATIONAL": 4,
      "ITERATIVE": 4,
      "STRUCTURAL": 5
    },
    "byLevel": {
      "intermediate": 8,
      "advanced": 5,
      "beginner": 5
    },
    "totalPromptsUsingPatterns": 201
  }
}
